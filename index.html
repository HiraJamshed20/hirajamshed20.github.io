<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Hira Jamshed</title>
  <meta name="description" content="Accessibility researcher at the University of Michigan. Projects, publications, and contact links." />
  <meta property="og:title" content="Hira Jamshed" />
  <meta property="og:description" content="Accessibility researcher at the University of Michigan. Projects, publications, and contact links." />
  <meta property="og:type" content="website" />
  <meta property="og:url" content="https://YOUR_USERNAME.github.io" />
  <meta name="color-scheme" content="light dark" />
  <link rel="icon" href="images/HJ.png" type="image/png">
  <link rel="apple-touch-icon" href="images/HJ.png">
  <link rel="stylesheet" href="styles.css" />
</head>
<body>
    <div class="wrap">

      <!-- Top bar with Michigan blue background
      <nav class="topbar" aria-label="Top navigation">
        <a href="#projects">Spotlight</a>
        <a href="#pubs">Publications &amp; Projects</a>
        <a href="#contact">Contact</a>
      </nav> -->

      <header>
        <div class="avatar"><img src="images/Hira.png" alt="Portrait of Hira Jamshed" /></div>
        <div class="title">
          <h1>Hira Jamshed</h1>
          <h2>Human‑AI Collaboration & Accessibility</h2>
          <p>School of Information, University of Michigan</p>
          <div class="linksbar" aria-label="quick links" style="margin-top:.4rem; display:flex; gap:.5rem; flex-wrap:wrap;">
            <span class="badge" title="Email"><span>📫</span><a href="mailto:hiraj@umich.edu">Email</a></span>
            <!-- <span class="badge" title="ORCID"><span>🧬</span><a href="https://orcid.org/0009-0007-6463-4394" rel="me">ORCID</a></span> -->
            <span class="badge" title="Curriculum Vitae"><span>📜</span><a href="cv.pdf">CV</a></span>
            <span class="badge" title="Google Scholar"><span>📚</span><a href="https://scholar.google.com/citations?user=_3KbIpsAAAAJ&hl=en" rel="me">Google Scholar</a></span>
            <span class="badge" title="LinkedIn"><span>🔗</span><a href="https://www.linkedin.com/in/hirajamshed/" rel="me">LinkedIn</a></span>
          </div>
        </div>
      </header>

      <section aria-labelledby="about">
        <div class="intro">
          <h2 id="about">👋 Hello!</h2>
          <p>
            I’m currently a third-year PhD candidate at the School of Information (UMSI) in the University of Michigan, where I work with <a href="https://robinbrewer.com">Prof. Robin Brewer</a> in the <a href="https://aha.si.umich.edu">Accessibility, Health, and Aging (AHA) Lab</a>. 
            My research focuses on empirical, methodological, and artifact-based contributions toward understanding how AI-based technologies shape everyday <em>reading, writing, and searching</em> practices, especially for older adults and people with visual and cognitive disabilities. 
            I am inspired by frameworks like <a href="https://dl.acm.org/doi/10.1145/3148051"><em>ability‑based design</em></a> and fields like <a href="https://dl.acm.org/doi/10.1145/3373625.3416996"><em>disability studies</em></a>, which urge reflective and personalised approaches to accessible interactive technologies.
          </p>
          <p>
            Before starting my PhD, I completed my masters in Human-Computer Interaction (with a focus in Accessibility) from the University of Texas at Austin (UT Austin) and my bachelors in Computer Science from Lahore University of Management Sciences (LUMS) in Pakistan.
            I have prior experience in product design and research (see my <a href="https://hirajamshed.webflow.io">portfolio</a>), and my publications include work in ACM CHI and ASSETS.   
          </p>
          <p>
            <strong>Current focus:</strong> Understanding and supporting how neurodivergent students and faculty adapt GenAI technologies in their everyday academic lives.
          </p>
      </section>

      <section aria-labelledby="projects">
        <h2 id="projects">Spotlight</h2>
        <div class="hlist">
          <ul class="spotlight-list"> 
            <li class="spotlight-item"><span class="marker">Oct</span><div><strong>2025 —</strong> My pre-candidacy project on understanding neurodivergent students' use of GenAI tools is headed to ASSETS'25 in Denver. See you there!</div></li>
            <li class="spotlight-item"><span class="marker">Sep</span><div><strong>2025 —</strong> Achieved Candidacy 🎉</div></li>
            <li class="spotlight-item"><span class="marker">Apr</span><div><strong>2025 —</strong> I will be presenting our work on accessible audio nudges at CHI'25 in Japan.</div></li>
            <li class="spotlight-item"><span class="marker">Mar</span><div><strong>2025 —</strong> Invited to speak about 'Embracing Neurodiversity in the Age of AI' at Oakland Community College. </div></li>
            <li class="spotlight-item"><span class="marker">Feb</span><div><strong>2025 —</strong> I got awarded the U‑M Provost Disability Scholarship Grant to study GenAI use among neurodivergent faculty and passed my pre-candidacy milestone!</div></li>
            <li class="spotlight-item"><span class="marker">Sep</span><div><strong>2023 —</strong> Coming in to ASSETS'23 as a student volunteer and a first-time attendee. </div></li>
          </ul>
        </div>
      </section>

      <section aria-labelledby="pubs">
        <h2 id="pubs">Projects and Publications</h2>
        <div class="hlist">
          <article class="hcard" aria-labelledby="grant-title">
            <div class="stamp" aria-hidden="true">🏛️</div>
            <div class="content">
              <h3 id="grant-title"> <a href=" https://www.si.umich.edu/about-umsi/news/hira-jamshed-earns-provosts-disability-scholarship-initiative-grant">Understanding ND Faculty’s GenAI Practices at U‑M</a></h3>
               <div class="meta"><strong>Team:</strong> <strong>Hira Jamshed (Principal Investigator)</strong>; Mustafa Naseem; Robin N. Brewer</div>
               <div class="meta"><strong>Funding Body:</strong> UofM Provost Disability Scholarship Initiative (2025)</div>
              <p> I am leading a two-year project that aims (1) uncover the professional challenges ND faculty face in their day-to-day roles (e.g., research, teaching, service), (2) identify where and how GenAI tools can offer the most support, and (3) understand ND faculty's perceptions and experiences with GenAI.
                Through a mixed-methods approach (i.e., surveys, interviews, and co-design workshops), we aim to provide actionable accessible design recommendations for U-M's GenAI tools, and foster community-building among ND faculty through the co-creation of a shared library of practical strategies and GenAI use cases.
              </p>
              <div class="actions">
                <a class="btn" href="https://provost.umich.edu/disability-scholarship-initiative/"> 🌐 About the Grant</a>
                <a class="btn" href="https://github.com/HiraJamshed20/DisabilityScholarshipInitiative/flyer.html">📝 Survey Call</a>
              </div>
            </div>
          </article>

          <!-- Paper A: Rethinking Productivity -->
          <article class="hcard">
            <div class="stamp" aria-hidden="true">🧠</div>
            <div class="content">
              <h3><a href="https://dl.acm.org/doi/10.1145/3663547.3746329" target="_blank" rel="noopener">Rethinking Productivity with GenAI: A Neurodivergent Students' Perspective</a></h3>
              <div class="meta"><strong>Authors:</strong> <strong>Hira Jamshed</strong>; Mustafa Naseem; Venkatesh Potluri; Robin N. Brewer</div>
              <div class="meta"><strong>Venue/Year:</strong> ASSETS 2025</div>
              <p> In response to calls for countering ableist narratives of lessening burdens and challenging normative norms that favor neurotypical individuals in prior research, this study interviewed (n = 19) neurodivergent students in higher-education regarding the use, motivation, and vision for LLM-based GenAI tools in academia. 
                  While students found the tools helpful, their experiences revealed challenges with integration into tried-and-tested workflows, limited AI literacy support, experimentation, and flattening personality. 
                  Drawing on crip time, the paper illustrates how GenAI tools can reinforce the normative value of productivity and shift the burden of access-making onto students themselves. 
                  We propose three design values (flexibility, adaptability, and self-authenticity) to reimagine GenAI as a partner rather than a tool prioritizing speed and self-sufficiency.</p>
              <div class="actions">
                <a class="btn" href="https://dl.acm.org/doi/pdf/10.1145/3663547.3746329" target="_blank" rel="noopener">📄 PDF</a>
                <a class="btn" href="https://dl.acm.org/doi/10.1145/3663547.3746329" target="_blank" rel="noopener">🔖 DOI</a>
              </div>
            </div>
          </article>

          <!-- Paper B: Audio Nudges -->
          <article class="hcard">
            <div class="stamp" aria-hidden="true">🔊</div>
            <div class="content">
              <h3><a href="https://dl.acm.org/doi/10.1145/3706598.3713563" target="_blank" rel="noopener">Designing Accessible Audio Nudges for Voice Interfaces</a></h3>
              <div class="meta"><strong>Authors:</strong> <strong>Hira Jamshed</strong>; Novia Nurain; Robin N. Brewer</div>
              <div class="meta"><strong>Venue/Year:</strong> CHI 2025</div>
              <p>This study extends nudging to voice-based systems to help older adults alleviate uncertainty in voice-based searches. 
                We evaluate four audio nudge prototypes (categorised into non-speech and speech-based nudges) with older adults (n = 34). 
                Findings show that speech nudges more effectively prompt critical reflection than non-speech nudges because they are more disruptive. 
                Therefore, we discuss the role of disruptiveness in accessibility, propose design considerations for implementing accessible audio nudges, and raise open questions for future research.</p>
              <div class="actions">
                <a class="btn" href="https://dl.acm.org/doi/pdf/10.1145/3706598.3713563" target="_blank" rel="noopener">📄 PDF</a>
                <a class="btn" href="https://dl.acm.org/doi/10.1145/3706598.3713563" target="_blank" rel="noopener">🔖 DOI</a>
              </div>
            </div>
          </article>

          <!-- Paper C: Care Partners -->
          <article class="hcard">
            <div class="stamp" aria-hidden="true">🏡</div>
            <div class="content">
              <h3><a href="https://dl.acm.org/doi/10.1145/3731562" target="_blank" rel="noopener">“I Felt Listened to”: Evaluating an AI-Powered Reflection Tool for Care Partners</a></h3>
              <div class="meta"><strong>Authors:</strong> Jazette Johnson; <strong>Hira Jamshed</strong>; Rachael Zuppke; Annalise Leggett; Emily Mower Provost; Robin N. Brewer</div>
              <div class="meta"><strong>Venue/Year:</strong> ACM Transactions on Accessible Computing (TOACCESS), 2025</div>
              <p>We evaluate CareJournal, an AI-powered application on an Amazon Alexa device, designed to address challenges faced by care partners in articulating the needs of the care relationships. 
                 Through a 4-week pilot study (N = 14 care partner pairs) and a 4-week field study (N = 16 care partner pairs), we assessed the tool’s effectiveness in supporting reflection and generating AI summaries that capture the care partners’ intent. 
                 Our findings indicate that CareJournal is a beneficial tool for improving communication intention and focus. 
                 We discuss design implications for AI to support articulation through adaptive reflection tools based on diverse care dynamics and highlight ethical considerations in balancing AI assistance with human agency.
              </p>
              <div class="actions">
                <a class="btn" href="https://dl.acm.org/doi/pdf/10.1145/3731562" target="_blank" rel="noopener">📄 PDF</a>
                <a class="btn" href="https://dl.acm.org/doi/10.1145/3731562" target="_blank" rel="noopener">🔖 DOI</a>
              </div>
            </div>
          </article>

          <!-- Paper D: DeepFakes -->
          <article class="hcard">
            <div class="stamp" aria-hidden="true">🎬</div>
            <div class="content">
              <h3><a href="https://dl.acm.org/doi/10.1145/3411764.3445699" target="_blank" rel="noopener">Seeing is Believing: Exploring Perceptual Differences in DeepFake Videos</a></h3>
              <div class="meta"><strong>Authors:</strong> Rashid Tahir; Bareera Batool; <strong>Hira Jamshed</strong>; Muhammad Jameel; Muhammad Anwar; Faiq Ahmed; Muhammad Ahmad Zaffar; Muhammad Fareed Zaffar</div>
              <div class="meta"><strong>Venue/Year:</strong> CHI 2021</div>
              <p>We perform an investigative user study and analyze existing AI detection algorithms from the literature to understand DeepFake detection.
                Based on our findings, we design a customized training program to improve detection and evaluate on a treatment group of low-literate population, which is most vulnerable to DeepFakes. 
                Our results suggest that, while DeepFakes are becoming imperceptible, contextualized education and training can help raise awareness and improve detection.
              </p>
              <div class="actions">
                <a class="btn" href="https://dl.acm.org/doi/pdf/10.1145/3411764.3445699" target="_blank" rel="noopener">📄 PDF</a>
                <a class="btn" href="https://dl.acm.org/doi/10.1145/3411764.3445699" target="_blank" rel="noopener">🔖 DOI</a>
              </div>
            </div>
          </article>
        </div>
      </section>

      <!-- <section aria-labelledby="contact">
        <h2 id="contact">Contact</h2>
        <p>Something</p>
      </section> -->

      <footer style="margin-top:2rem; color:var(--muted); font-size:.9rem">
        <span>© <span id="y"></span> Hira Jamshed </span> 
      </footer>
    </div>

    <script>
      // Keep year current
      document.getElementById('y').textContent = new Date().getFullYear();

      // Vertically center single-line spotlight items
      (function () {
        const compute = () => {
          document.querySelectorAll('.spotlight-item').forEach(item => {
            const content = item.querySelector('.marker + div, .content, div'); // flexible selector
            if (!content) return;
            const cs = window.getComputedStyle(content);
            const lineHeight = parseFloat(cs.lineHeight) || parseFloat(cs.fontSize) * 1.2;
            const lines = Math.round(content.scrollHeight / lineHeight);
            if (lines <= 1) item.classList.add('single-line');
            else item.classList.remove('single-line');
          });
        };
        // run on load and resize (debounced)
        let t;
        window.addEventListener('load', compute);
        window.addEventListener('resize', () => { clearTimeout(t); t = setTimeout(compute, 120); });

        // observe dynamic changes to spotlight list
        const list = document.querySelector('.spotlight-list');
        if (list) {
          const mo = new MutationObserver(() => compute());
          mo.observe(list, { childList: true, subtree: true, characterData: true });
        }
      })();
    </script>
  </body>
</html>
